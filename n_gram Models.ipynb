{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram  Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from __future__ import division\n",
    "from functools import partial,reduce\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import *\n",
    "\n",
    "import math,random,re,requests\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Functality\n",
    "def fix_unicode(text):\n",
    "    return text.replace(u\"\\u2019\",\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document():\n",
    "\n",
    "    url = \"http://radar.oreilly.com/2010/06/what-is-data-science.html\"\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    content = soup.find(\"div\", \"article-body\")         # find article-body div\n",
    "    regex = r\"[\\w']+|[\\.]\"                             # matches a word or a period\n",
    "\n",
    "    document = []\n",
    "\n",
    "\n",
    "    for paragraph in content(\"p\"):\n",
    "        words = re.findall(regex, fix_unicode(paragraph.text))\n",
    "        document.extend(words)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = get_document()\n",
    "\n",
    "bigrams = list(zip(document, document[1:]))\n",
    "transitions = defaultdict(list)\n",
    "for prev, current in bigrams:\n",
    "    transitions[prev].append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Information Platforms as awk to turn around faces cars or incongruous do massive correlations across an audio all of data creatively to understanding the 70s were too low 1 012 Twitter a data source R is also frequently missing do with more frequently missing or analyzing musical problem from traditional data source implementation of ozone layer depletion was a camera and increase of a thousand data we're trying to a web server your local supermarket is the wild and then looking at Cloudera which there was a spreadsheet .\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_using_biagrams():\n",
    "    current = \".\"\n",
    "    result = []\n",
    "    while True:\n",
    "        next_word_candidate = transitions[current]\n",
    "        current = random.choice(next_word_candidate)\n",
    "        result.append(current)\n",
    "        if current == '.':return \" \".join(result)\n",
    "generate_using_biagrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = zip(document,document[1:],document[2:])\n",
    "trigram_transition = defaultdict(list)\n",
    "starts = []\n",
    "for prev,current,next in trigrams:\n",
    "    if prev == \".\":\n",
    "        starts.append(current)\n",
    "    trigram_transition[(prev,current)].append(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A picture may or may not be worth a thousand numbers .'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_using_trigram():\n",
    "    current = random.choice(starts)\n",
    "    prev = \".\"\n",
    "    result = [current]\n",
    "    while True:\n",
    "        next_word_candidates = trigram_transition[(prev,current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "        prev,current = current,next_word\n",
    "        result.append(current)\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 => 0 and of Moore's Law comes in not just an application with data run out of steam .\n",
      "2 => That's the foundation of data jiujitsu using smaller auxiliary problems to solve a much more tractable problem that gave them the same conclusion .\n",
      "3 => Many of these databases are the logical descendants of Google's BigTable and Amazon's Dynamo and are designed for exploring and understanding the data you can't just throw the data you will find to put Hadoop to work with very broadly defined problems here's a lot of data .\n",
      "4 => Statistics plays a role in any data analysis enables features like trending topics don't require millisecond accuracy .\n",
      "5 => The more storage is available the more data in the database including a CD you've taken advantage of this data would be useless if we couldn't store it .\n",
      "6 => The Turk is an excellent way to develop and tune the application .\n",
      "7 => The web has people spending more time online and leaving a trail of data products that help to drive Amazon's more traditional retail business .\n",
      "8 => They can think outside the box to come up with new ways to view the problem .\n",
      "9 => Many of the data that's available and relevant .\n",
      "10 => According to Hilary Mason hmason data scientist at LinkedIn dpatil the best data scientists started looking at events that members attended .\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i+1,\"=>\",generate_using_trigram())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(token):\n",
    "    return token[0] != \"_\"\n",
    "def expand(grammer,tokens):\n",
    "    for i,token in enumerate(tokens):\n",
    "        if is_terminal(token): \n",
    "            continue\n",
    "        #Random choice\n",
    "        replacement = random.choice(grammar[token])\n",
    "        if is_terminal(replacement):\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            print(\"ss\",replacement.split(),tokens)\n",
    "            tokens = tokens[:i]  + replacement.split() + tokens[(i+1):]\n",
    "            print(\"s\",tokens)\n",
    "        return expand(grammer,tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss ['_NP', '_VP'] ['_S']\n",
      "s ['_NP', '_VP']\n",
      "ss ['_N'] ['_NP', '_VP']\n",
      "s ['_N', '_VP']\n",
      "ss ['_V'] ['regression', '_VP']\n",
      "s ['regression', '_V']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'regression is'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sentence(grammar):\n",
    "    return \" \".join(expand(grammar, [\"_S\"]))\n",
    "in_grammer = {\n",
    "    \"_S\" : [\"_NP _VP\"],\n",
    "    \"_NP\" : [\"_N\",\n",
    "    \"_A _NP _P _A _N\"],\n",
    "    \"_VP\" : [\"_V\",\n",
    "    \"_V _NP\"],\n",
    "    \"_N\" : [\"data science\", \"Python\", \"regression\"],\n",
    "    \"_A\" : [\"big\", \"linear\", \"logistic\"],\n",
    "    \"_P\" : [\"about\", \"near\"],\n",
    "    \"_V\" : [\"learns\", \"trains\", \"tests\", \"is\"]\n",
    "}\n",
    "generate_sentence(in_grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
